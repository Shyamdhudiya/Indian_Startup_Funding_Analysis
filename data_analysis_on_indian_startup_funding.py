# -*- coding: utf-8 -*-
"""Data-analysis-on-indian-startup-funding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/130454icen44k8Zg6sxJtfVtx9MALfTlW
"""

# Data handling
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

# Visualisation (Matplotlib, Plotly, Seaborn, etc.)
import seaborn as sns
import matplotlib.pyplot as plt

# Feature processing (Scilit-learn processing, etc.)
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

from google.colab import files
uploaded = files.upload()

"""# **Data** **Loading**"""

sheet1=pd.read_csv("startup_funding2018.csv")
sheet2=pd.read_csv("startup_funding2019.csv")
sheet3=pd.read_csv("startup_funding2020.csv")
sheet4=pd.read_csv("startup_funding2021.csv")

"""# Dataset Overview"""

# checking the shape of each file
print(sheet1.shape)
print(sheet2.shape)
print(sheet3.shape)
print(sheet4.shape)

print("sheet1",sheet1.head(5))
print("sheet2", sheet2.head(5))
print("sheet3", sheet3.head(5))
print("sheet4", sheet4.head(5))

sheet1.info()

sheet2.info()

sheet3.info()

sheet4.info()

sheet1.isnull().sum()

sheet2.isnull().sum()

sheet3.isnull().sum()

sheet4.isnull().sum()

"""# **Issues with the data**
1. column names of sheet1 are different from the others
2. sheet3 has an unnecessary column('Unnamed: 9')
3. sheet1 doesn't have columns Founders,Investor and Founded.
4. sheet1 amount column has rupees, dollars, commas and is a string
5. amount column of other sheets have dollars, commas and is a string
6. there are null values in the founded, headquater, sector and stage columns
7. headquater column for sheet1 has more information
8. for the sector column, the values are different in all
9. amount column has null values
10. datatypes are mostly object

# **How we intend to handle each issue identified**
1. change column names of sheet1 to match the others
2. drop unnecessary column in sheet3
3. add missing columns to sheet1 with null values
4. convert sheet1 amount column to dollars in float
5. convert amount of other sheets to dollars in float
6. we'll leave the null values since they are not numbers
7. separate by commas and keep only the first word in headquater column for sheet1
8. make the values similar for example: 8. "Ecommerce" and "E-Commerce Platforms" should be "E-commerce"
9. replace null values in amount column by calculating the mean or median
10. change datatypes accordingly for each column

# **Data Cleaning**
"""

# 1. Change column namesof sheet1 to match the others
sheet1.rename(columns = {'Company Name': 'Company/Brand', 'Industry':'Sector',
                              'Round/Series':'Stage', 'Amount':'Amount($)',
                        'Location':'HeadQuarter', 'About Company':'What it does'}, inplace = True)

sheet1.head(1)

# 2. Drop unnecessary column in sheet3
sheet3.drop('Unnamed: 9', axis=1, inplace=True)

sheet3.info()

# 3. Add missing columns to sheet1 with null values
sheet1['Founders'] = np.nan
sheet1['Investor'] = np.nan
sheet1['Founded'] = np.nan

# 4. Convert sheet1 amount column to dollars in flot
def amountCleaner(sheet):
  sheet['Amount($)'] = sheet['Amount($)'].apply(lambda x: str(x).replace('—','NaN').replace(',','').replace('Undisclosed','NaN').replace('Upsparks','NaN').replace('Series C','NaN').replace('undisclosed','NaN').replace('ah! Ventures','NaN').replace('Pre-series A','NaN').replace('ITO Angel Network LetsVenture','NaN').replace('JITO Angel Network LetsVenture','NaN').replace('Seed','NaN').replace('JNaN','NaN').replace('800000000 to 850000000','825000000').replace('Undiclsosed','').replace('887000 23000000','11943500').replace('Undislosed','NaN').replace('$',''))
amountCleaner(sheet1)

# convert rupees to dollars if it has rupees sign
sheet1['Amount($)'] = sheet1['Amount($)'].apply(
    lambda x: float(str(x).replace('₹',''))*0.012 if '₹' in x
else x)

sheet1.head(2)

amountCleaner(sheet2)
amountCleaner(sheet3)
amountCleaner(sheet4)

# 5. Convert amount of other sheets to dollars in float


sheet1['Amount($)'] = sheet1['Amount($)'].replace('NaN',np.nan).replace('nan',np.nan)
sheet2['Amount($)'] = sheet2['Amount($)'].replace('NaN',np.nan).replace('nan',np.nan)
sheet4['Amount($)'] = sheet4['Amount($)'].replace('NaN',np.nan).replace('nan',np.nan)
sheet1['Amount($)'] = pd.to_numeric(sheet1['Amount($)'], downcast = 'float')
sheet2['Amount($)'] = pd.to_numeric(sheet2['Amount($)'], downcast = 'float')
sheet4['Amount($)'] = pd.to_numeric(sheet4['Amount($)'], downcast = 'float')

sheet3['Amount($)'] = sheet3['Amount($)'].astype(str).str.replace(',', '').str.strip()
sheet3['Amount($)'] = sheet3['Amount($)'].str.extract(r'(\d+\.?\d*)')[0]
sheet3['Amount($)'] = pd.to_numeric(sheet3['Amount($)'], errors='coerce', downcast='float')

# 7. Separate by commas and keep only the first word in headquater column for sheet1

sheet1[['HeadQuarter','s','f']] = sheet1['HeadQuarter'].str.split(', ',expand=True)
sheet1.drop(columns=['s','f'], axis=1, inplace = True)

sheet1.head(5)

# 8. Make the values similar for example: 8. "Ecommerce" and "E-Commerce Platforms" should be "E-commerce"

sheet2['Sector'] = sheet2['Sector'].replace('Ecommerce','E-commerce')
sheet2['Sector'].unique()

# 10. change datatypes accordingly for each column

# Convert the various sheet to it respective data types
# Sheet1
sheet1['Founded'] = sheet1['Founded'].astype('Int64')
sheet1['Founders'] = sheet1['Founders'].astype('object')
sheet1['Investor'] = sheet1['Investor'].astype('object')

# Sheet 2
sheet2['Founded'] = sheet2['Founded'].astype('Int64')

# Sheet 3
sheet3['Founded'] = sheet3['Founded'].replace('-',np.nan)
sheet3['Founded'] = sheet3['Founded'].astype('Int64')

# Sheet 4
sheet4['Founded'] = sheet4['Founded'].astype('Int64')

"""# Merge The Datasets"""

Data = pd.concat([sheet1,sheet2,sheet3,sheet4])
Data

Data.info()

(Data.duplicated()).sum()

Data.loc[Data.duplicated(),:]

# Drop the row
Data.drop_duplicates(keep='first')

"""# Outliers within the dataset"""

plt.figure(figsize=(12,10))
sns.boxplot(data=Data['Amount($)'],palette='Blues_d')
plt.show()

"""# Using the simpleImputer to replace NaN values

"""

def replacer(Strategy, column):
    imputer = SimpleImputer(strategy=Strategy, missing_values=np.nan)
    imputer = imputer.fit(Data[[column]])
    Data[column] = imputer.transform(Data[[column]]).ravel()

replacer('mean', 'Amount($)')
replacer('most_frequent', 'Stage')
replacer('most_frequent', 'HeadQuarter')
replacer('most_frequent', 'Sector')
replacer('most_frequent', 'Founders')
replacer('most_frequent', 'Investor')
replacer('most_frequent', 'Founded')

Data.isnull().sum()

Data.head(5)

Data.shape

Data['HeadQuarter'].unique()

Data.describe()

"""# QUESTIONS"""

# 1. Which company has the highest amount of funds?

top_companies = Data.groupby("Company/Brand")["Amount($)"].sum().reset_index().sort_values(by="Amount($)",ascending=False)
top_companies

fig = plt.figure(figsize=(12,5))
plt.title("top_companies")
sns.barplot(data=top_companies.iloc[:5] , x="Amount($)", y="Company/Brand", palette='Blues_d')

fig.show()

# 2. Which location has the minimum startup funds?

Location_with_least_amount = Data.groupby("HeadQuarter")["Amount($)"].sum().reset_index().sort_values(by="Amount($)",ascending=True)
Location_with_least_amount

fig = plt.figure(figsize=(12,5))
plt.title("Location_with_least_amount")
sns.barplot(data=Location_with_least_amount.iloc[:5] , x="Amount($)", y="HeadQuarter", palette='Blues_d')
fig.show()

# 3. In which sector has the top 5 investors

Top_Sectors = Data.groupby("Sector")["Amount($)"].sum().reset_index().sort_values(by="Amount($)",ascending=False).iloc[:5]
Top_Sectors

fig = plt.figure(figsize=(20,10))
plt.title("Top_Sectors")
sns.barplot(data=Top_Sectors.iloc[:5] , y="Amount($)", x="Sector", palette='Blues_d')
fig.show()

# 4. How much did the investors contributed in Delhi and Mumbai?

D1 = Data.iloc[:, [4,3]]
x = ['Delhi', 'Mumbai']
D2 = D1[D1['HeadQuarter'].isin(x)]
D2.groupby("HeadQuarter")["Amount($)"].sum().reset_index().sort_values(by="Amount($)",ascending=False)

fig = plt.figure(figsize=(12,5))
plt.title("Amount Contributed in Delhi and Mumbai")
sns.barplot(data=D2 , y="Amount($)", x="HeadQuarter", palette=['red','green'])
fig.show()

"""# Univariate Analysis"""

Data['HeadQuarter'].value_counts(normalize=True)

#plot the bar graph of HeadQuarter categories
plt.title(' HeadQuarter categories')
Data['HeadQuarter'].iloc[:10].value_counts(normalize=True).plot.barh()
plt.show()

Data['Stage'].value_counts(normalize=True)

#plot pie chart of Stage categories
plt.title('Stage categories')
Data['Stage'].iloc[:10].value_counts(normalize=True).plot.pie()
plt.show()

Data['Amount($)'].value_counts(normalize=True)

#plot pie chart of Amount categories
plt.title('Amount($) Categories')
Data['Amount($)'].iloc[:10].value_counts(normalize=True).plot.kde()
plt.show()

Data.hist(bins = 50, figsize = (10,5))
plt.show()

"""# Multivariate analysis"""

Data.select_dtypes(include='number').corr()

sns.set(font_scale = 1.15)

sns.heatmap(
    Data.select_dtypes(include='number').corr(),
    cmap = 'RdBu_r',
    annot = True,
    vmin = -1, vmax = 1);

sns.scatterplot(
    y = 'Amount($)',
    x = 'Founded',
    data = Data.iloc[:5],
    palette = 'bright',
    hue = 'HeadQuarter');

sns.lmplot(
    y = 'Amount($)',
    x = 'Founded',
    data = Data.iloc[:5],
    palette = 'bright',
    col = 'Stage',
    hue = 'HeadQuarter');

sns.barplot(
    y = 'Amount($)',
    x = 'Founded',
    data = Data.iloc[:10],
    palette = 'bright',
    hue = 'Company/Brand');

"""# Scaling

### Scale the numerical features using the Scikif-learn Standard Scaler
"""

scaler = MinMaxScaler()
array = scaler.fit_transform(Data[['Founded','Amount($)']])
array

pd.DataFrame(array,columns = ['Amount($)','Founded'])

array.shape

Data.shape

"""# Encoding"""

Data.keys()

df2 = pd.get_dummies(data = Data, columns = ['Company/Brand', 'Sector', 'Stage', 'HeadQuarter','What it does', 'Founders', 'Investor'])
df2.columns

df2.sample(5)

df2.shape

